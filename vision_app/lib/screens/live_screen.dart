import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:flutter_svg/flutter_svg.dart';
import 'package:camera/camera.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:image/image.dart' as img;
import 'package:audio_session/audio_session.dart';
import 'package:http/http.dart' as http;
import 'live_screen_with_buttons.dart';
import 'chat_screen.dart';
import 'customer_service_screen.dart';
import 'elli_home_screen.dart';
import 'video_production_screen.dart';
import '../services/live_camera_service.dart';
import '../config/api_config.dart';

// -----------------------------------------------------------------------------
// Isolate Functions for Image Conversion (No Changes)
// -----------------------------------------------------------------------------
Future<String?> convertYUV420ToBase64(Map<String, dynamic> params) async {
  try {
    final int width = params['width'];
    final int height = params['height'];
    final Uint8List yPlane = params['yPlane'];
    final Uint8List uPlane = params['uPlane'];
    final Uint8List vPlane = params['vPlane'];
    final int yRowStride = params['yRowStride'];
    final int uvRowStride = params['uvRowStride'];
    final int uvPixelStride = params['uvPixelStride'];

    final img.Image image = img.Image(width: width, height: height);

    for (int y = 0; y < height; y++) {
      for (int x = 0; x < width; x++) {
        final int uvIndex =
            uvPixelStride * (x / 2).floor() + uvRowStride * (y / 2).floor();
        final int yIndex = y * yRowStride + x;

        final int yp = yPlane[yIndex];
        final int up = uPlane[uvIndex];
        final int vp = vPlane[uvIndex];

        int r = (yp + 1.402 * (vp - 128)).round().clamp(0, 255);
        int g = (yp - 0.344136 * (up - 128) - 0.714136 * (vp - 128))
            .round()
            .clamp(0, 255);
        int b = (yp + 1.772 * (up - 128)).round().clamp(0, 255);

        image.setPixelRgb(x, y, r, g, b);
      }
    }

    return base64Encode(img.encodeJpg(image, quality: 50));
  } catch (e) {
    debugPrint("YUV Conversion Error: $e");
    return null;
  }
}

Future<String?> convertBGRAToBase64(Map<String, dynamic> params) async {
  try {
    final int width = params['width'];
    final int height = params['height'];
    final Uint8List bgraPlane = params['bgraPlane'];

    final img.Image image = img.Image.fromBytes(
      width: width,
      height: height,
      bytes: bgraPlane.buffer,
      order: img.ChannelOrder.bgra,
    );

    return base64Encode(img.encodeJpg(image, quality: 50));
  } catch (e) {
    debugPrint("BGRA Conversion Error: $e");
    return null;
  }
}

// -----------------------------------------------------------------------------
// Main LiveScreen Widget
// -----------------------------------------------------------------------------
class LiveScreen extends StatefulWidget {
  const LiveScreen({super.key});

  @override
  State<LiveScreen> createState() => _LiveScreenState();
}

class _LiveScreenState extends State<LiveScreen> {
  final LiveCameraService _cameraService = LiveCameraService();
  bool _isStreaming = false;

  // Figma í”„ë ˆì„ í¬ê¸°: 360x800
  static const double figmaWidth = 360;

  // Gemini Live ê´€ë ¨ ìƒíƒœ
  CameraController? _cameraController;
  WebSocketChannel? _channel;
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final FlutterSoundPlayer _player = FlutterSoundPlayer();

  bool _isCameraInitialized = false;

  DateTime _lastFrameTime = DateTime.now();
  bool _isProcessingFrame = false;

  // [ìˆ˜ì •ë¨] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸
  bool _isAudioPlayerReady = false;

  // âš ï¸ ìì‹ ì˜ PC IP ì£¼ì†Œë¡œ ë³€ê²½ í•„ìš”
  // Android Emulator: 10.0.2.2, Real Device: 192.168.x.x
  final String _wsUrl = 'ws://192.168.0.47:8000/ws/chat';

  // Audio Stream Controller
  final StreamController<Uint8List> _audioStreamController =
      StreamController<Uint8List>();
  StreamSink<Uint8List> get _audioStreamSink => _audioStreamController.sink;

  String _aiResponseText = "ì œê°€ ë„ì™€ë“œë¦´ê²Œìš”, ì—˜ì§€ë‹˜!\nì˜¤ë¥˜ ìƒí™©ì„ ë³´ì—¬ì£¼ì‹œê² ì–´ìš”?";

  // Buffer to accumulate text parts for the current response
  String _currentResponseBuffer = "";
  String? _currentResponseId;

  @override
  void initState() {
    super.initState();
    _initializePermissions();
    _handleAudioStream();
    // ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™ ì½œë°± ì„¤ì •
    _cameraService.setOnExitRequested(() {
      if (mounted) {
        _cameraService.stopStreaming();
        Navigator.pushAndRemoveUntil(
          context,
          MaterialPageRoute(builder: (context) => const ElliHomeScreen()),
          (route) => false,
        );
      }
    });
  }

  Future<void> _initializePermissions() async {
    await [Permission.camera, Permission.microphone].request();
    await _initializeCamera();
    await _initializeAudio();

    // Auto start streaming after initialization
    if (_isCameraInitialized) {
      _startStreaming();
    }
  }

  Future<void> _initializeCamera() async {
    final cameras = await availableCameras();
    if (cameras.isEmpty) return;

    _cameraController = CameraController(
      cameras.first,
      ResolutionPreset.medium,
      enableAudio: false,
    );

    await _cameraController!.initialize();
    setState(() {
      _isCameraInitialized = true;
    });

    if (_isCameraInitialized) {
      _startStreaming();
    }
  }

  Future<void> _initializeAudio() async {
    final session = await AudioSession.instance;
    await session.configure(
      const AudioSessionConfiguration(
        avAudioSessionCategory: AVAudioSessionCategory.playAndRecord,
        avAudioSessionCategoryOptions:
            AVAudioSessionCategoryOptions.defaultToSpeaker,
        avAudioSessionMode: AVAudioSessionMode.defaultMode,
        avAudioSessionRouteSharingPolicy:
            AVAudioSessionRouteSharingPolicy.defaultPolicy,
        avAudioSessionSetActiveOptions: AVAudioSessionSetActiveOptions.none,
        androidAudioAttributes: AndroidAudioAttributes(
          contentType: AndroidAudioContentType.music,
          flags: AndroidAudioFlags.none,
          usage: AndroidAudioUsage.media,
        ),
        androidAudioFocusGainType: AndroidAudioFocusGainType.gain,
        androidWillPauseWhenDucked: true,
      ),
    );

    await _recorder.openRecorder();
    await _player.openPlayer();
  }

  void _connectWebSocket() {
    try {
      _channel = WebSocketChannel.connect(Uri.parse(_wsUrl));
      print("âœ… WebSocket Connected");

      _channel!.stream.listen(
        (message) {
          if (message is List<int>) {
            // Binary Audio from Server
            _playAudioChunk(Uint8List.fromList(message));
          } else {
            _handleServerMessage(message);
          }
        },
        onError: (error) {
          print("âŒ WebSocket Error: $error");
          _stopStreaming();
        },
        onDone: () {
          print("ğŸ”Œ WebSocket Closed");
          _stopStreaming();
        },
      );
    } catch (e) {
      print("âŒ Connection Failed: $e");
    }
  }

  void _handleServerMessage(dynamic message) async {
    try {
      final decoded = jsonDecode(message);
      final type = decoded['type'];
      final data = decoded['data'];
      final id = decoded['id'];

      if (type == 'audio_partial') {
        final audioBytes = base64Decode(data);
        await _playAudioChunk(audioBytes);
      } else if (type == 'text_partial') {
        setState(() {
          if (id != null && id != _currentResponseId) {
            _currentResponseId = id;
            _currentResponseBuffer = "";
          }
          _currentResponseBuffer += data;
          _aiResponseText = _currentResponseBuffer;
        });
      } else if (type == 'text') {
        setState(() {
          _aiResponseText = data;
        });
      } else if (type == 'turn_complete') {
        // Handle end of turn logic if needed
      }
    } catch (e) {
      print("Message Error: $e");
    }
  }

  // [ìˆ˜ì •ë¨] ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ í•¨ìˆ˜: ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
  Future<void> _playAudioChunk(Uint8List data) async {
    if (data.isEmpty) return;

    try {
      // 1. í”Œë ˆì´ì–´ ìŠ¤íŠ¸ë¦¼ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ë‹¤ë©´ 1íšŒë§Œ ì‹œì‘
      if (!_isAudioPlayerReady) {
        await _player.startPlayerFromStream(
          codec: Codec.pcm16,
          numChannels: 1, // Mono
          sampleRate: 24000, // ì„œë²„(OpenAI) ì„¤ì •ê³¼ ì¼ì¹˜í•´ì•¼ í•¨
          bufferSize: 8192,
          interleaved: false,
        );
        _isAudioPlayerReady = true;
      }

      // 2. ì¤€ë¹„ëœ ìŠ¤íŠ¸ë¦¼ì— ë°ì´í„°ë§Œ ê³„ì† ì£¼ì…
      await _player.feedFromStream(data);
    } catch (e) {
      print("Audio Playback Error: $e");
      // ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„ ë¡œì§ì´ë‚˜ ìƒíƒœ ì´ˆê¸°í™”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
    }
  }

  Future<void> _startStreaming() async {
    if (!_isCameraInitialized) return;
    if (_channel == null) _connectWebSocket();
    if (_isStreaming) return;

    setState(() {
      _isStreaming = true;
    });

    // 1. Start Audio Recording Stream
    await _recorder.startRecorder(
      toStream: _audioStreamSink,
      codec: Codec.pcm16,
      numChannels: 1,
      sampleRate: 24000,
    );

    // 2. Start Video Stream (Throttle ~10 FPS)
    await _cameraController!.startImageStream((CameraImage image) {
      if (_isProcessingFrame) return;
      if (DateTime.now().difference(_lastFrameTime).inMilliseconds < 100)
        return;

      _isProcessingFrame = true;
      _lastFrameTime = DateTime.now();
      _processCameraImage(image);
    });
  }

  void _processCameraImage(CameraImage image) {
    final int width = image.width;
    final int height = image.height;

    if (image.format.group == ImageFormatGroup.yuv420) {
      final Uint8List yPlane = Uint8List.fromList(image.planes[0].bytes);
      final Uint8List uPlane = Uint8List.fromList(image.planes[1].bytes);
      final Uint8List vPlane = Uint8List.fromList(image.planes[2].bytes);
      final int yRowStride = image.planes[0].bytesPerRow;
      final int uvRowStride = image.planes[1].bytesPerRow;
      final int uvPixelStride = image.planes[1].bytesPerPixel!;

      compute(convertYUV420ToBase64, {
        'width': width,
        'height': height,
        'yPlane': yPlane,
        'uPlane': uPlane,
        'vPlane': vPlane,
        'yRowStride': yRowStride,
        'uvRowStride': uvRowStride,
        'uvPixelStride': uvPixelStride,
      }).then((base64Result) {
        if (base64Result != null && _isStreaming && _channel != null) {
          _channel!.sink.add(
            jsonEncode({"type": "image_base64", "data": base64Result}),
          );
        }
        _isProcessingFrame = false;
      });
    } else if (image.format.group == ImageFormatGroup.bgra8888) {
      final Uint8List bgraPlane = Uint8List.fromList(image.planes[0].bytes);
      compute(convertBGRAToBase64, {
        'width': width,
        'height': height,
        'bgraPlane': bgraPlane,
      }).then((base64Result) {
        if (base64Result != null && _isStreaming && _channel != null) {
          _channel!.sink.add(
            jsonEncode({"type": "image_base64", "data": base64Result}),
          );
        }
        _isProcessingFrame = false;
      });
    } else {
      _isProcessingFrame = false;
    }
  }

  void _handleAudioStream() {
    _audioStreamController.stream.listen((data) {
      if (_isStreaming && _channel != null) {
        _channel!.sink.add(data);
      }
    });
  }

  Future<void> _stopStreaming() async {
    setState(() {
      _isStreaming = false;
    });

    if (_cameraController != null &&
        _cameraController!.value.isStreamingImages) {
      await _cameraController!.stopImageStream();
    }

    await _recorder.stopRecorder();
    await _player.stopPlayer();

    // [ì¤‘ìš”] ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì‹œ í”Œë ˆì´ì–´ ìƒíƒœ ì´ˆê¸°í™”
    _isAudioPlayerReady = false;

    _channel?.sink.close();
    _channel = null;
  }

  @override
  void dispose() {
    _recorder.closeRecorder();
    _player.closePlayer();
    _cameraController?.dispose();
    _audioStreamController.close();
    _cameraService.stopStreaming();
    super.dispose();
  }

  static const double figmaHeight = 800;

  @override
  Widget build(BuildContext context) {
    SystemChrome.setSystemUIOverlayStyle(
      const SystemUiOverlayStyle(
        statusBarColor: Color(0xFFFAF9FD),
        statusBarIconBrightness: Brightness.dark,
        systemNavigationBarColor: Color(0xFFF4F2FD),
        systemNavigationBarIconBrightness: Brightness.dark,
      ),
    );

    final mediaQuery = MediaQuery.of(context);
    final screenWidth = mediaQuery.size.width;
    final screenHeight = mediaQuery.size.height;
    final scale = screenWidth / figmaWidth;

    return Scaffold(
      backgroundColor: const Color(0xFFF3F1FB),
      body: SizedBox(
        width: screenWidth,
        height: screenHeight,
        child: Stack(
          children: [
            // ë°°ê²½ ê·¸ë¼ë°ì´ì…˜
            Positioned(
              top: 24 * scale,
              left: 0,
              right: 0,
              bottom: 0,
              child: Container(
                decoration: const BoxDecoration(
                  gradient: LinearGradient(
                    begin: Alignment.topCenter,
                    end: Alignment.bottomCenter,
                    colors: [Color(0xFFF3F1FB), Color(0xFF7145F1)],
                    stops: [0.42, 1.0],
                  ),
                ),
              ),
            ),
            // ìƒíƒœë°” ì˜ì—­
            Positioned(
              top: 0,
              left: 0,
              right: 0,
              height: 24 * scale,
              child: Container(color: const Color(0xFFFAF9FD)),
            ),
            // "ì‹¤ì‹œê°„ ì§„ë‹¨" í…ìŠ¤íŠ¸
            Positioned(
              top: 70 * scale,
              left: 23 * scale,
              child: Row(
                children: [
                  Container(
                    width: 9 * scale,
                    height: 9 * scale,
                    decoration: const BoxDecoration(
                      shape: BoxShape.circle,
                      color: Color(0xFFFF0004),
                    ),
                  ),
                  SizedBox(width: 10 * scale),
                  Text(
                    'ì‹¤ì‹œê°„ ì§„ë‹¨',
                    style: TextStyle(
                      fontFamily: 'Noto Sans',
                      fontSize: 16 * scale,
                      fontWeight: FontWeight.w500,
                      color: Colors.black,
                      letterSpacing: 0.016 * scale,
                      height: 21.792 / 16,
                    ),
                  ),
                ],
              ),
            ),
            // ì˜¤ë¥¸ìª½ ìƒë‹¨ ì•„ì´ì½˜ë“¤
            // ì˜¤ë¥¸ìª½ ìƒë‹¨ ì•„ì´ì½˜ ë²„íŠ¼ë“¤ (í”¼ê·¸ë§ˆ ë””ìì¸ì— ë§ê²Œ ìˆ˜ì •)
            // Figma: left-[271px], top-[68px], gap-[15px]
            Positioned(
              top: 68 * scale,
              left: 271 * scale,
              child: Row(
                mainAxisSize: MainAxisSize.min,
                children: [
                  // ì±„íŒ… ì•„ì´ì½˜ (message-text-02)
                  // Figma: size-[24px]
                  GestureDetector(
                    onTap: () {
                      Navigator.push(
                        context,
                        MaterialPageRoute(
                          builder: (context) => const ChatScreen(),
                        ),
                      );
                    },
                    child: SvgPicture.asset(
                      'assets/images/ë¼ì´ë¸Œìƒë‹¨ì•„ì´ì½˜.svg',
                      width: 24 * scale,
                      height: 24 * scale,
                    ),
                  ),
                  SizedBox(width: 15 * scale), // gap-[15px]
                  // ì¬ìƒ ë¦¬ìŠ¤íŠ¸ ì•„ì´ì½˜ (play-list) - generate.py ì‹¤í–‰
                  // Figma: size-[21px]
                  GestureDetector(
                    onTap: () async {
                      // 1. ë°±ì—”ë“œ generate.py ì‹¤í–‰ ìš”ì²­ (ë¹„ë™ê¸°)
                      try {
                        final url = Uri.parse(
                          '${ApiConfig.baseUrl}/generate-video',
                        );
                        http
                            .post(url)
                            .then((response) {
                              print(
                                "Generation trigger response: ${response.statusCode}",
                              );
                            })
                            .catchError((error) {
                              print("Generation trigger error: $error");
                            });
                      } catch (e) {
                        print("Error triggering generation: $e");
                      }

                      // 2. í™”ë©´ ì´ë™
                      Navigator.push(
                        context,
                        MaterialPageRoute(
                          builder: (context) => const VideoProductionScreen(),
                        ),
                      );
                    },
                    child: Container(
                      width: 21 * scale,
                      height: 21 * scale,
                      color: Colors.transparent,
                      // ì¬ìƒ ë¦¬ìŠ¤íŠ¸ ì•„ì´ì½˜ SVG (assetsì— ìˆë‹¤ê³  ê°€ì •, ì—†ìœ¼ë©´ ë‹¤ë¥¸ ì•„ì´ì½˜ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
                      child: Icon(
                        Icons.playlist_play,
                        size: 21 * scale,
                        color: Colors.black,
                      ),
                    ),
                  ),
                  SizedBox(width: 15 * scale), // gap-[15px]
                  // í—¤ë“œì…‹ ì•„ì´ì½˜ (Group)
                  // Figma: size-[22.286px]
                  GestureDetector(
                    onTap: () {
                      Navigator.push(
                        context,
                        MaterialPageRoute(
                          builder: (context) => const CustomerServiceScreen(),
                        ),
                      );
                    },
                    child: SvgPicture.asset(
                      'assets/images/ë¼ì´ë¸Œìƒë‹¨ì•„ì´ì½˜2.svg',
                      width: 22.286 * scale,
                      height: 22.286 * scale,
                    ),
                  ),
                ],
              ),
            ),
            // ì¤‘ì•™ ë¹„ë””ì˜¤ ì˜ì—­ (ì¹´ë©”ë¼ í”„ë¦¬ë·°)
            // Figma: top:112, left:0, width:360, height:554
            Positioned(
              top: 112 * scale,
              left: 0,
              right: 0,
              height: 554 * scale,
              child: Container(
                margin: EdgeInsets.symmetric(horizontal: 0),
                decoration: BoxDecoration(
                  color: const Color(0xFFEFEFF0),
                  border: Border.all(
                    color: const Color(0xFFAFB1B6),
                    width: 2 * scale,
                  ),
                  borderRadius: BorderRadius.circular(8 * scale),
                ),
                child: ClipRRect(
                  borderRadius: BorderRadius.circular(8 * scale),
                  child:
                      _cameraService.cameraController != null &&
                          _cameraService.cameraController!.value.isInitialized
                      ? SizedBox(
                          width: double.infinity,
                          height: double.infinity,
                          child: CameraPreview(
                            _cameraService.cameraController!,
                          ),
                        )
                      : Center(
                          child: Icon(
                            Icons.videocam,
                            size: 60 * scale,
                            color: const Color(0xFFAFB1B6),
                          ),
                        ),
                ),
              ),
            ),
            // ìºë¦­í„° ì´ë¯¸ì§€
            Positioned(
              top: 509 * scale,
              left: 19 * scale,
              child: Image.asset(
                'assets/images/ìºë¦­í„° ì •ì§€.png',
                width: 95 * scale,
                height: 143 * scale,
                fit: BoxFit.cover,
                errorBuilder: (context, error, stackTrace) {
                  return Container(
                    width: 95 * scale,
                    height: 143 * scale,
                    color: Colors.grey.withValues(alpha: 0.3),
                    child: Icon(
                      Icons.person,
                      size: 40 * scale,
                      color: Colors.grey,
                    ),
                  );
                },
              ),
            ),
            // ë§í’ì„ 
            Positioned(
              top: 509 * scale,
              left: (19 + 95 + 10) * scale,
              child: GestureDetector(
                onTap: () => Navigator.push(
                  context,
                  MaterialPageRoute(
                    builder: (context) => const LiveScreenWithButtons(),
                  ),
                ),
                child: Container(
                  width: 223 * scale,
                  height: 80 * scale,
                  decoration: BoxDecoration(
                    color: const Color(0xFFD9D9D9).withValues(alpha: 0.49),
                    borderRadius: BorderRadius.circular(15 * scale),
                  ),
                  padding: EdgeInsets.symmetric(
                    horizontal: 32 * scale,
                    vertical: 22 * scale,
                  ),
                  child: Center(
                    child: Text(
                      _aiResponseText,
                      style: TextStyle(
                        fontFamily: 'Noto Sans',
                        fontSize: 13 * scale,
                        fontWeight: FontWeight.w400,
                        color: Colors.black,
                        letterSpacing: 0.2 * scale,
                        height: 17.706 / 13,
                      ),
                      textAlign: TextAlign.center,
                    ),
                  ),
                ),
              ),
            ),
            // í•˜ë‹¨ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ë“¤
            Positioned(
              top: 687 * scale,
              left: 57 * scale,
              child: GestureDetector(
                onTap: () async {
                  if (_isStreaming) {
                    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
                    await _cameraService.stopStreaming();
                    setState(() {
                      _isStreaming = false;
                    });
                    if (mounted) {
                      ScaffoldMessenger.of(context).showSnackBar(
                        const SnackBar(content: Text('ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.')),
                      );
                    }
                  } else {
                    // ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
                    if (mounted) {
                      ScaffoldMessenger.of(context).showSnackBar(
                        const SnackBar(content: Text('ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‹œì‘í•©ë‹ˆë‹¤...')),
                      );
                    }
                    final success = await _cameraService.startStreaming(
                      context,
                    );
                    if (success) {
                      setState(() {
                        _isStreaming = true;
                      });
                      // ì¹´ë©”ë¼ ì´ˆê¸°í™” í›„ UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ì•½ê°„ì˜ ì§€ì—° í›„ ë‹¤ì‹œ setState
                      await Future.delayed(const Duration(milliseconds: 300));
                      if (mounted) {
                        setState(() {}); // ì¹´ë©”ë¼ í”„ë¦¬ë·° í‘œì‹œë¥¼ ìœ„í•´ UI ì—…ë°ì´íŠ¸
                      }
                      if (mounted) {
                        ScaffoldMessenger.of(context).showSnackBar(
                          const SnackBar(content: Text('ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.')),
                        );
                      }
                    } else {
                      if (mounted) {
                        ScaffoldMessenger.of(context).showSnackBar(
                          const SnackBar(
                            content: Text('ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.'),
                          ),
                        );
                      }
                    }
                  }
                },
                child: Container(
                  width: 66 * scale,
                  height: 44 * scale,
                  decoration: BoxDecoration(
                    color: _isStreaming ? Colors.red : Colors.white,
                    borderRadius: BorderRadius.circular(19.5 * scale),
                    boxShadow: [
                      BoxShadow(
                        color: Colors.black.withValues(alpha: 0.25),
                        blurRadius: 4 * scale,
                        offset: Offset(0, 4 * scale),
                      ),
                    ],
                  ),
                  child: Center(
                    child: Icon(
                      _isStreaming ? Icons.stop : Icons.videocam,
                      size: 24 * scale,
                      color: _isStreaming ? Colors.white : Colors.black,
                    ),
                  ),
                ),
              ),
            ),
            Positioned(
              top: 687 * scale,
              left: 147 * scale,
              child: Container(
                width: 66 * scale,
                height: 44 * scale,
                decoration: BoxDecoration(
                  borderRadius: BorderRadius.circular(19.5 * scale),
                  boxShadow: [
                    BoxShadow(
                      color: Colors.black.withValues(alpha: 0.25),
                      blurRadius: 4 * scale,
                      offset: Offset(0, 4 * scale),
                    ),
                  ],
                ),
                child: ClipRRect(
                  borderRadius: BorderRadius.circular(19.5 * scale),
                  child: Image.asset(
                    'assets/images/ë¼ì´ë¸Œ ì¬ìƒ ë²„íŠ¼.png',
                    width: 66 * scale,
                    height: 44 * scale,
                    fit: BoxFit.cover,
                    errorBuilder: (context, error, stackTrace) {
                      return Container(
                        width: 66 * scale,
                        height: 44 * scale,
                        color: const Color(0xFF29344E).withValues(alpha: 0.54),
                      );
                    },
                  ),
                ),
              ),
            ),
            // ì„¸ ë²ˆì§¸ ë²„íŠ¼ (Rectangle 291): Frame ë‚´ë¶€ x=180, y=0, width=66, height=44
            // X ë²„íŠ¼: ì§„ë‹¨ í™”ë©´ ì¢…ë£Œ ë° ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™
            Positioned(
              top: 687 * scale,
              left: 237 * scale,
              child: GestureDetector(
                onTap: () {
                  // 1. WebSocket ì„œë¹„ìŠ¤ì— ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
                  _cameraService.closeDiagnosisAndExit();

                  // 2. ì ì‹œ ëŒ€ê¸° í›„ ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™ (ì„œë²„ ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ì´ë™)
                  Future.delayed(const Duration(milliseconds: 500), () {
                    if (mounted) {
                      // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
                      _cameraService.stopStreaming();
                      // ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™
                      Navigator.pushAndRemoveUntil(
                        context,
                        MaterialPageRoute(
                          builder: (context) => const ElliHomeScreen(),
                        ),
                        (route) => false,
                      );
                    }
                  });
                },
                child: Container(
                  width: 66 * scale,
                  height: 44 * scale,
                  decoration: BoxDecoration(
                    color: const Color(0xFFF41919),
                    borderRadius: BorderRadius.circular(19.5 * scale),
                    boxShadow: [
                      BoxShadow(
                        color: Colors.black.withValues(alpha: 0.25),
                        blurRadius: 4 * scale,
                        offset: Offset(0, 4 * scale),
                      ),
                    ],
                  ),
                  child: Center(
                    child: Icon(
                      Icons.close,
                      size: 24 * scale,
                      color: Colors.white,
                    ),
                  ),
                ),
              ),
            ),
          ],
        ),
      ),
    );
  }
}
