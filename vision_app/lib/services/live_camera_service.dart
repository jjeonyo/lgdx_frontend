import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:camera/camera.dart';
import 'package:cloud_firestore/cloud_firestore.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:record/record.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:flutter/material.dart';

class LiveCameraService {
  // ğŸ”¥ í•«ìŠ¤íŒŸ ì—°ê²° ì‹œ: PC IP ì£¼ì†Œë¥¼ ipconfigë¡œ í™•ì¸ í›„ ì•„ë˜ IPë¥¼ ë³€ê²½í•˜ì„¸ìš”!
  // ğŸ’¡ í•«ìŠ¤íŒŸë³„ IP ëŒ€ì—­:
  //    - iPhone í•«ìŠ¤íŒŸ: 172.20.10.x
  //    - Android í•«ìŠ¤íŒŸ: 192.168.43.x ë˜ëŠ” 192.168.137.x
  //    - ì¼ë°˜ Wi-Fi: 192.168.0.x ë˜ëŠ” 192.168.1.x
  static const String REAL_DEVICE_IP = "192.168.0.27"; // PC IP ì£¼ì†Œ (ipconfigë¡œ í™•ì¸)
  static const String WS_URL = "ws://$REAL_DEVICE_IP:8001/ws/chat"; // test.pyëŠ” í¬íŠ¸ 8001 ì‚¬ìš©
  
  CameraController? _cameraController;
  WebSocketChannel? _channel;
  StreamSubscription? _websocketSubscription;
  Timer? _videoTimer;
  Timer? _audioTimer;
  AudioRecorder? _audioRecorder;
  StreamSubscription? _audioStreamSubscription;
  AudioPlayer? _audioPlayer; // AI ì˜¤ë””ì˜¤ ì¬ìƒìš©
  final List<File> _audioQueue = []; // ì˜¤ë””ì˜¤ ì¬ìƒ í
  bool _isPlayingAudio = false; // ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ í”Œë˜ê·¸
  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ëê¹Œì§€ ì´ì–´ë¶™ì´ëŠ” ë²„í¼
  final List<Uint8List> _pendingAudioChunks = [];
  Timer? _audioFlushTimer; // ì˜¤ë””ì˜¤ ë²„í¼ í”ŒëŸ¬ì‹œ íƒ€ì´ë¨¸
  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: í˜„ì¬ í„´ì˜ ëª¨ë“  ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ëˆ„ì  (ëê¹Œì§€ ë°›ê¸°)
  Uint8List? _currentTurnAudioBuffer; // í˜„ì¬ í„´ì˜ ì˜¤ë””ì˜¤ ë²„í¼
  // ì‚¬ìš©ì ë§í•˜ê¸° ê°ì§€ìš© íƒ€ì´ë¨¸
  Timer? _userSpeechTimer; // ì‚¬ìš©ìê°€ ë§ì„ ë©ˆì·„ëŠ”ì§€ ê°ì§€
  DateTime? _lastAudioSentTime; // ë§ˆì§€ë§‰ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œê°„
  
  bool _isStreaming = false;
  String? _sessionId;
  String? _roomId; // chat_room ID (room_user_001 í˜•ì‹)
  VoidCallback? _onExitRequested; // ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™ ì½œë°±
  
  // Firebaseì— í…ìŠ¤íŠ¸ ì €ì¥ (chat_roomsì— ì €ì¥)
  Future<void> _saveToFirebase(String sender, String text) async {
    try {
      if (_roomId == null) {
        print("âš ï¸ [LiveCamera] roomIdê°€ ì—†ì–´ Firebaseì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }
      
      // ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
      if (text.isEmpty || text.trim().isEmpty) {
        print("âš ï¸ [LiveCamera] ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
        return;
      }
      
      // AI ì‘ë‹µì¸ ê²½ìš° ì˜ì–´ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ (í•œêµ­ì–´ë§Œ ì €ì¥)
      if (sender == 'gemini') {
        if (_isEnglishOnly(text)) {
          print("âš ï¸ [LiveCamera] ì˜ì–´ë§Œ í¬í•¨ëœ AI ì‘ë‹µì€ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${text.substring(0, text.length > 50 ? 50 : text.length)}...");
          return;
        }
        // í•œêµ­ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì €ì¥
        if (!_containsKorean(text)) {
          print("âš ï¸ [LiveCamera] í•œêµ­ì–´ê°€ í¬í•¨ë˜ì§€ ì•Šì€ AI ì‘ë‹µì€ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${text.substring(0, text.length > 50 ? 50 : text.length)}...");
          return;
        }
      }
      
      final timestamp = DateTime.now();
      
      // íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë°©í™”ë²½ ë¬¸ì œ ì™„í™”
      await FirebaseFirestore.instance
          .collection('chat_rooms')
          .doc(_roomId)
          .collection('messages')
          .add({
        'sender': sender,
        'text': text,
        'message_type': 'live', // ë¼ì´ë¸Œ ëŒ€í™”ëŠ” ëª¨ë‘ 'live'ë¡œ ì €ì¥
        'timestamp': FieldValue.serverTimestamp(),
        'created_at': timestamp.millisecondsSinceEpoch,
        'timezone': 'KST',
      }).timeout(
        const Duration(seconds: 10),
        onTimeout: () {
          throw TimeoutException('Firebase ì €ì¥ ì‹œê°„ ì´ˆê³¼ (ë°©í™”ë²½ ë¬¸ì œ ê°€ëŠ¥ì„±)');
        },
      );
      
      print("âœ… [LiveCamera] Firebase ì €ì¥ ì„±ê³µ (chat_rooms/$_roomId/messages) - sender: $sender, text: ${text.substring(0, text.length > 50 ? 50 : text.length)}...");
    } on TimeoutException catch (e) {
      print("â±ï¸ [LiveCamera] Firebase ì €ì¥ ì‹œê°„ ì´ˆê³¼: $e");
      print("   ë°©í™”ë²½ì´ Firebase ì—°ê²°ì„ ì°¨ë‹¨í•˜ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.");
      print("   Windows ë°©í™”ë²½ì—ì„œ Firebase ë„ë©”ì¸ì„ í—ˆìš©í•˜ê±°ë‚˜, ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.");
    } catch (e) {
      print("âŒ [LiveCamera] Firebase ì €ì¥ ì‹¤íŒ¨: $e");
      // ë°©í™”ë²½ ê´€ë ¨ ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
      if (e.toString().contains('firewall') || 
          e.toString().contains('ë°©í™”ë²½') ||
          e.toString().contains('network') ||
          e.toString().contains('unreachable')) {
        print("   ğŸ”¥ ë°©í™”ë²½ ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:");
        print("   1. Windows ë°©í™”ë²½ì—ì„œ Firebase ë„ë©”ì¸ í—ˆìš©");
        print("   2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸");
        print("   3. VPNì´ë‚˜ í”„ë¡ì‹œ ì„¤ì • í™•ì¸");
      }
    }
  }
  
  // ê¶Œí•œ ìš”ì²­ (BuildContextë¥¼ ë°›ì•„ì„œ ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ ê°€ëŠ¥)
  Future<bool> requestPermissions(BuildContext? context) async {
    try {
      print("ğŸ” [LiveCamera] ê¶Œí•œ ìš”ì²­ ì‹œì‘");
      
      // ë¨¼ì € í˜„ì¬ ê¶Œí•œ ìƒíƒœ í™•ì¸
      final cameraStatus = await Permission.camera.status;
      final microphoneStatus = await Permission.microphone.status;
      
      print("ğŸ” [LiveCamera] í˜„ì¬ ê¶Œí•œ ìƒíƒœ - ì¹´ë©”ë¼: $cameraStatus, ë§ˆì´í¬: $microphoneStatus");
      
      // ì´ë¯¸ ê¶Œí•œì´ ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
      if (cameraStatus.isGranted && microphoneStatus.isGranted) {
        print("âœ… [LiveCamera] ê¶Œí•œ ì´ë¯¸ ìŠ¹ì¸ë¨");
        return true;
      }
      
      // ê¶Œí•œì´ ì˜êµ¬ì ìœ¼ë¡œ ê±°ë¶€ëœ ê²½ìš° ì„¤ì •ìœ¼ë¡œ ì´ë™
      if (cameraStatus.isPermanentlyDenied || microphoneStatus.isPermanentlyDenied) {
        print("âš ï¸ [LiveCamera] ê¶Œí•œì´ ì˜êµ¬ì ìœ¼ë¡œ ê±°ë¶€ë¨ - ì„¤ì •ìœ¼ë¡œ ì´ë™ í•„ìš”");
        if (context != null && context.mounted) {
          _showPermissionDialog(context);
        }
        return false;
      }
      
      // ê¶Œí•œ ìš”ì²­ (ìˆœì°¨ì ìœ¼ë¡œ ìš”ì²­í•˜ì—¬ ì¶©ëŒ ë°©ì§€)
      print("ğŸ” [LiveCamera] ì¹´ë©”ë¼ ê¶Œí•œ ìš”ì²­ ì¤‘...");
      PermissionStatus cameraResult = cameraStatus;
      if (!cameraStatus.isGranted) {
        cameraResult = await Permission.camera.request();
        print("ğŸ” [LiveCamera] ì¹´ë©”ë¼ ê¶Œí•œ ê²°ê³¼: $cameraResult");
      }
      
      // ì ì‹œ ëŒ€ê¸° (ê¶Œí•œ íŒì—…ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡)
      await Future.delayed(const Duration(milliseconds: 300));
      
      print("ğŸ” [LiveCamera] ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...");
      PermissionStatus microphoneResult = microphoneStatus;
      if (!microphoneStatus.isGranted) {
        microphoneResult = await Permission.microphone.request();
        print("ğŸ” [LiveCamera] ë§ˆì´í¬ ê¶Œí•œ ê²°ê³¼: $microphoneResult");
      }
      
      // ìµœì¢… ê¶Œí•œ ìƒíƒœ í™•ì¸
      final finalCameraStatus = await Permission.camera.status;
      final finalMicrophoneStatus = await Permission.microphone.status;
      
      if (finalCameraStatus.isGranted && finalMicrophoneStatus.isGranted) {
        print("âœ… [LiveCamera] ê¶Œí•œ ìŠ¹ì¸ ì™„ë£Œ");
        return true;
      } else {
        print("âŒ [LiveCamera] ê¶Œí•œ ê±°ë¶€ë¨ - ì¹´ë©”ë¼: $finalCameraStatus, ë§ˆì´í¬: $finalMicrophoneStatus");
        
        // ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆê³ , ì˜êµ¬ì ìœ¼ë¡œ ê±°ë¶€ë˜ì§€ ì•Šì€ ê²½ìš° ë‹¤ì‹œ ìš”ì²­
        if (finalCameraStatus.isPermanentlyDenied || finalMicrophoneStatus.isPermanentlyDenied) {
          // ì˜êµ¬ì ìœ¼ë¡œ ê±°ë¶€ëœ ê²½ìš° ì„¤ì •ìœ¼ë¡œ ì´ë™
          if (context != null && context.mounted) {
            _showPermissionDialog(context);
          }
        } else {
          // ì¼ì‹œì ìœ¼ë¡œ ê±°ë¶€ëœ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€
          if (context != null && context.mounted) {
            _showPermissionDeniedDialog(context);
          }
        }
        return false;
      }
    } catch (e, stackTrace) {
      print("âŒ [LiveCamera] ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨: $e");
      print("âŒ [LiveCamera] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: $stackTrace");
      if (context != null && context.mounted) {
        _showPermissionErrorDialog(context, e.toString());
      }
      return false;
    }
  }
  
  // ê¶Œí•œ ê±°ë¶€ ë‹¤ì´ì–¼ë¡œê·¸ (ì„¤ì •ìœ¼ë¡œ ì´ë™)
  void _showPermissionDialog(BuildContext context) {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: const Text('ê¶Œí•œ í•„ìš”'),
          content: const Text(
            'ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.\n\n'
            'ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”:\n'
            '1. "ì„¤ì •ìœ¼ë¡œ ì´ë™" ë²„íŠ¼ í´ë¦­\n'
            '2. ê¶Œí•œ > ì¹´ë©”ë¼ í—ˆìš©\n'
            '3. ê¶Œí•œ > ë§ˆì´í¬ í—ˆìš©\n'
            '4. ì•±ìœ¼ë¡œ ëŒì•„ì™€ì„œ ë‹¤ì‹œ ì‹œë„',
          ),
          actions: [
            TextButton(
              onPressed: () {
                Navigator.of(context).pop();
              },
              child: const Text('ë‚˜ì¤‘ì—'),
            ),
            TextButton(
              onPressed: () async {
                Navigator.of(context).pop();
                await openAppSettings();
              },
              child: const Text('ì„¤ì •ìœ¼ë¡œ ì´ë™'),
            ),
          ],
        );
      },
    );
  }
  
  // ê¶Œí•œ ê±°ë¶€ ë‹¤ì´ì–¼ë¡œê·¸ (ì¼ì‹œì  ê±°ë¶€)
  void _showPermissionDeniedDialog(BuildContext context) {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: const Text('ê¶Œí•œ í•„ìš”'),
          content: const Text(
            'ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.\n\n'
            'ë‹¤ì‹œ ì‹œë„í•˜ë©´ ê¶Œí•œ ìš”ì²­ íŒì—…ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n'
            'íŒì—…ì—ì„œ "í—ˆìš©"ì„ ì„ íƒí•´ì£¼ì„¸ìš”.',
          ),
          actions: [
            TextButton(
              onPressed: () {
                Navigator.of(context).pop();
              },
              child: const Text('í™•ì¸'),
            ),
          ],
        );
      },
    );
  }
  
  // ê¶Œí•œ ìš”ì²­ ì—ëŸ¬ ë‹¤ì´ì–¼ë¡œê·¸
  void _showPermissionErrorDialog(BuildContext context, String error) {
    showDialog(
      context: context,
      builder: (BuildContext context) {
        return AlertDialog(
          title: const Text('ì˜¤ë¥˜'),
          content: Text('ê¶Œí•œ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: $error\n\nì•±ì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ ì„¤ì •ì—ì„œ ì§ì ‘ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.'),
          actions: [
            TextButton(
              onPressed: () {
                Navigator.of(context).pop();
              },
              child: const Text('í™•ì¸'),
            ),
            TextButton(
              onPressed: () async {
                Navigator.of(context).pop();
                await openAppSettings();
              },
              child: const Text('ì„¤ì •ìœ¼ë¡œ ì´ë™'),
            ),
          ],
        );
      },
    );
  }
  
  // ì¹´ë©”ë¼ ì´ˆê¸°í™”
  Future<bool> initializeCamera() async {
    try {
      final cameras = await availableCameras();
      if (cameras.isEmpty) {
        print("âŒ [LiveCamera] ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤.");
        return false;
      }
      
      // í›„ë©´ ì¹´ë©”ë¼ ìš°ì„ , ì—†ìœ¼ë©´ ì „ë©´ ì¹´ë©”ë¼
      final camera = cameras.firstWhere(
        (camera) => camera.lensDirection == CameraLensDirection.back,
        orElse: () => cameras.first,
      );
      
      print("ğŸ“¹ [LiveCamera] ì„ íƒëœ ì¹´ë©”ë¼: ${camera.lensDirection == CameraLensDirection.back ? 'í›„ë©´' : 'ì „ë©´'}");
      
      _cameraController = CameraController(
        camera,
        ResolutionPreset.medium,
        enableAudio: true,
      );
      
      await _cameraController!.initialize();
      print("âœ… [LiveCamera] ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ (${camera.lensDirection == CameraLensDirection.back ? 'í›„ë©´' : 'ì „ë©´'})");
      return true;
    } catch (e) {
      print("âŒ [LiveCamera] ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: $e");
      return false;
    }
  }
  
  // WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
  Future<bool> _testWebSocketConnection() async {
    try {
      print("ğŸ” [LiveCamera] ë°±ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘: $WS_URL");
      final testChannel = WebSocketChannel.connect(Uri.parse(WS_URL));
      
      // ì—°ê²° íƒ€ì„ì•„ì›ƒ ì„¤ì • (5ì´ˆ)
      await testChannel.ready.timeout(
        const Duration(seconds: 5),
        onTimeout: () {
          testChannel.sink.close();
          throw TimeoutException('ë°±ì—”ë“œ ì„œë²„ ì—°ê²° ì‹œê°„ ì´ˆê³¼ (5ì´ˆ)');
        },
      );
      
      await testChannel.sink.close();
      print("âœ… [LiveCamera] ë°±ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ");
      return true;
    } on TimeoutException catch (e) {
      print("âŒ [LiveCamera] ë°±ì—”ë“œ ì—°ê²° ì‹œê°„ ì´ˆê³¼: $e");
      return false;
    } on SocketException catch (e) {
      print("âŒ [LiveCamera] ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨: $e");
      return false;
    } catch (e) {
      print("âŒ [LiveCamera] ë°±ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: $e");
      return false;
    }
  }
  
  // WebSocket ì—°ê²° ë° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
  Future<bool> startStreaming(BuildContext? context) async {
    try {
      // 1ë‹¨ê³„: ê¶Œí•œ í™•ì¸
      print("ğŸ” [LiveCamera] 1ë‹¨ê³„: ê¶Œí•œ í™•ì¸");
      if (!await requestPermissions(context)) {
        print("âŒ [LiveCamera] ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨");
        return false;
      }
      print("âœ… [LiveCamera] ê¶Œí•œ í™•ì¸ ì™„ë£Œ");
      
      // 2ë‹¨ê³„: ì¹´ë©”ë¼ ì´ˆê¸°í™”
      print("ğŸ“¹ [LiveCamera] 2ë‹¨ê³„: ì¹´ë©”ë¼ ì´ˆê¸°í™”");
      if (!await initializeCamera()) {
        print("âŒ [LiveCamera] ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨");
        return false;
      }
      print("âœ… [LiveCamera] ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ");
      
      // 3ë‹¨ê³„: ë°±ì—”ë“œ ì„œë²„ ì—°ê²° í™•ì¸
      print("ğŸ” [LiveCamera] 3ë‹¨ê³„: ë°±ì—”ë“œ ì„œë²„ ì—°ê²° í™•ì¸");
      final backendAvailable = await _testWebSocketConnection();
      if (!backendAvailable) {
        if (context != null && context.mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(
              content: Text('ë°±ì—”ë“œ ì„œë²„ ì—°ê²° ì‹¤íŒ¨. ì¹´ë©”ë¼ëŠ” ì‘ë™í•˜ì§€ë§Œ ìŠ¤íŠ¸ë¦¬ë°ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.'),
              duration: Duration(seconds: 3),
            ),
          );
        }
        print("âš ï¸ [LiveCamera] ë°±ì—”ë“œ ì„œë²„ ì—°ê²° ì‹¤íŒ¨ - ì¹´ë©”ë¼ëŠ” ì‘ë™í•˜ì§€ë§Œ ìŠ¤íŠ¸ë¦¬ë° ë¶ˆê°€");
        return true;
      }
      print("âœ… [LiveCamera] ë°±ì—”ë“œ ì„œë²„ ì—°ê²° í™•ì¸ ì™„ë£Œ");
      
      // 4ë‹¨ê³„: WebSocket ì—°ê²°
      print("ğŸŒ [LiveCamera] 4ë‹¨ê³„: WebSocket ì—°ê²°");
      try {
        _channel = WebSocketChannel.connect(Uri.parse(WS_URL));
        await Future.delayed(const Duration(milliseconds: 500));
        
        if (_channel != null) {
          try {
            await _channel!.ready.timeout(
              const Duration(seconds: 2),
              onTimeout: () {
                throw TimeoutException('WebSocket ì—°ê²° ì‹œê°„ ì´ˆê³¼');
              },
            );
            print("âœ… [LiveCamera] WebSocket ì—°ê²° ì™„ë£Œ: $WS_URL");
          } catch (e) {
            print("âš ï¸ [LiveCamera] WebSocket ì—°ê²° í™•ì¸ ì‹¤íŒ¨: $e");
            _channel?.sink.close();
            _channel = null;
          }
        }
      } catch (e) {
        print("âš ï¸ [LiveCamera] WebSocket ì—°ê²° ì‹¤íŒ¨: $e");
        _channel?.sink.close();
        _channel = null;
      }
      
      // ì„¸ì…˜ ID ìƒì„±
      _sessionId = DateTime.now().millisecondsSinceEpoch.toString();
      const userId = 'user_001';
      _roomId = 'room_$userId';
      
      // Firebase chat_room ìƒì„±
      try {
        final roomRef = FirebaseFirestore.instance.collection('chat_rooms').doc(_roomId);
        final roomDoc = await roomRef.get().timeout(
          const Duration(seconds: 10),
          onTimeout: () => throw TimeoutException('Firebase ì—°ê²° ì‹œê°„ ì´ˆê³¼'),
        );
        
        if (!roomDoc.exists) {
          await roomRef.set({
            'user_id': userId,
            'created_at': FieldValue.serverTimestamp(),
            'last_message_at': FieldValue.serverTimestamp(),
          }).timeout(const Duration(seconds: 10));
          print("âœ… [LiveCamera] Firebase chat_room ìƒì„±: $_roomId");
        } else {
          await roomRef.update({
            'last_message_at': FieldValue.serverTimestamp(),
          }).timeout(const Duration(seconds: 10));
          print("âœ… [LiveCamera] Firebase chat_room ì‚¬ìš©: $_roomId");
        }
      } catch (e) {
        print("âš ï¸ [LiveCamera] Firebase chat_room ìƒì„±/ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: $e");
      }
      
      _isStreaming = true;
      
      // ë°±ì—”ë“œ ì—°ê²°ëœ ê²½ìš°ì—ë§Œ WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  ë° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
      if (_channel != null) {
        // ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì´ˆê¸°í™”
        try {
          _audioPlayer = AudioPlayer();
          // â­ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •: ë¯¸ë””ì–´ ë³¼ë¥¨ìœ¼ë¡œ ì¬ìƒí•˜ì—¬ ë” í¬ê²Œ ë“¤ë¦¬ë„ë¡ í•¨
          await _audioPlayer!.setAudioContext(AudioContext(
            android: AudioContextAndroid(
              isSpeakerphoneOn: true, // ìŠ¤í”¼ì»¤í° ê°•ì œ í™œì„±í™”
              audioMode: AndroidAudioMode.normal, // ì¼ë°˜ ëª¨ë“œ (ë¯¸ë””ì–´ ë³¼ë¥¨ ì‚¬ìš©)
              stayAwake: false,
              contentType: AndroidContentType.music, // ìŒì•…ìœ¼ë¡œ ì„¤ì • (ë¯¸ë””ì–´ ë³¼ë¥¨)
              usageType: AndroidUsageType.media, // ë¯¸ë””ì–´ ì¬ìƒìœ¼ë¡œ ì„¤ì • (ë¯¸ë””ì–´ ë³¼ë¥¨ ì‚¬ìš©)
              audioFocus: AndroidAudioFocus.gain, // ê°•í•œ ì˜¤ë””ì˜¤ í¬ì»¤ìŠ¤
            ),
            iOS: AudioContextIOS(
              category: AVAudioSessionCategory.playAndRecord, // ë…¹ìŒê³¼ ì¬ìƒ ë™ì‹œ ì§€ì›
              options: {
                AVAudioSessionOptions.defaultToSpeaker, // ìŠ¤í”¼ì»¤ë¡œ ê¸°ë³¸ ì¶œë ¥
                AVAudioSessionOptions.mixWithOthers, // ë‹¤ë¥¸ ì˜¤ë””ì˜¤ì™€ í˜¼í•© í—ˆìš©
              },
            ),
          ));
          _audioPlayer!.setPlayerMode(PlayerMode.lowLatency);
          
          // â­ ì¤‘ìš”: ë³¼ë¥¨ì„ ëª…ì‹œì ìœ¼ë¡œ ìµœëŒ€ë¡œ ì„¤ì •
          await _audioPlayer!.setVolume(1.0);
          
          // â­ ì¤‘ìš”: ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ë¦´ë¦¬ì¦ˆí•˜ì§€ ì•ŠìŒ
          // ì´ë ‡ê²Œ í•˜ë©´ ì˜¤ë””ì˜¤ í¬ì»¤ìŠ¤ë¥¼ ê³„ì† ìœ ì§€í•˜ì—¬ ë…¹ìŒì„ ë°©í•´í•˜ì§€ ì•ŠìŒ
          await _audioPlayer!.setReleaseMode(ReleaseMode.stop);

          // ì¬ìƒ ìƒíƒœë¥¼ ì¶”ì í•˜ì—¬ í ì²˜ë¦¬ ì¬ê°œ
          _audioPlayer!.onPlayerStateChanged.listen((state) {
            print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ìƒíƒœ ë³€ê²½: $state");
            _isPlayingAudio = state == PlayerState.playing;
            if (!_isPlayingAudio) {
              _processAudioQueue();
            }
          });
          _audioPlayer!.onPlayerComplete.listen((_) {
            print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ìˆ˜ì‹ ");
            _isPlayingAudio = false;
            _processAudioQueue();
          });
          
          // ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì—ëŸ¬ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
          _audioPlayer!.onLog.listen((message) {
            print("ğŸ“ [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ë¡œê·¸: $message");
          });
          
          _isPlayingAudio = false;
          print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì´ˆê¸°í™” ì™„ë£Œ (lowLatency ëª¨ë“œ)");
          print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ìƒíƒœ: ${_audioPlayer!.state}");
        } catch (e) {
          print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: $e");
        }
        
        // WebSocket ë©”ì‹œì§€ ìˆ˜ì‹ 
        _websocketSubscription = _channel!.stream.listen(
          (message) {
            try {
              final data = jsonDecode(message);
              
              // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
              if (data['type'] == 'text' && data['data'] != null) {
                final text = data['data'] as String;
                if (text.isNotEmpty && text.trim().isNotEmpty) {
                  print("ğŸ“ [LiveCamera] AI ì‘ë‹µ ìˆ˜ì‹ : $text");
                  _saveToFirebase('gemini', text);
                }
              }
              
              // ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì²˜ë¦¬ (ê³µì‹ ì˜ˆì œ íŒ¨í„´: response.dataë¥¼ ëê¹Œì§€ ì´ì–´ë¶™ì„)
              if (data['type'] == 'audio' && data['data'] != null) {
                try {
                  final audioBase64 = data['data'] as String;
                  final audioBytes = base64Decode(audioBase64);
                  
                  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ í„´ ë²„í¼ì— ì´ì–´ë¶™ì„
                  _appendAudioChunk(audioBytes);
                } catch (e) {
                  print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: $e");
                }
              }
              
              // í„´ ì™„ë£Œ ì‹ í˜¸ ì²˜ë¦¬
              // X ë²„íŠ¼ì„ ëˆ„ë¥´ê¸° ì „ê¹Œì§€ëŠ” ì˜¤ë””ì˜¤ë¥¼ ì •ìƒì ìœ¼ë¡œ ì¬ìƒ
              // X ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì˜¤ë””ì˜¤ ì¬ìƒì„ ì¤‘ë‹¨í•˜ê³  í™ˆìœ¼ë¡œ ì´ë™
              if (data['type'] == 'turn_complete') {
                final shouldExit = data['exit'] ?? false;
                print("âœ… [LiveCamera] í„´ ì™„ë£Œ ì‹ í˜¸ ìˆ˜ì‹  (exit: $shouldExit)");
                
                // AI ì‘ë‹µì´ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ë©”ì‹œì§€ ì €ì¥
                if (!shouldExit) {
                  // X ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¶”ê°€ ë©”ì‹œì§€ ì €ì¥ (ëŒ€í™”ê°€ ê³„ì†ë˜ëŠ” ê²½ìš°)
                  const videoMessage = "ì§€ê¸ˆê¹Œì§€ ëŒ€í™” ë‚˜ëˆˆ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ai ê¸°ë°˜ ë¬¸ì œ í•´ê²° ì˜ìƒì„ ë³´ê³  ì‹¶ë‹¤ë©´ ì˜¤ë¥¸ìª½ ìœ„ì— ë™ì˜ìƒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”";
                  _saveToFirebase('gemini', videoMessage);
                }
                
                if (shouldExit) {
                  // X ë²„íŠ¼ì„ ëˆ„ë¥¸ ê²½ìš°: ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ë‹¨ ë° í™ˆìœ¼ë¡œ ì´ë™
                  print("âœ… [LiveCamera] X ë²„íŠ¼ í´ë¦­ ê°ì§€ - ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ë‹¨ ë° í™ˆìœ¼ë¡œ ì´ë™");
                  
                  // 1. í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¤‘ë‹¨
                  _audioPlayer?.stop();
                  _isPlayingAudio = false;
                  
                  // 2. ì˜¤ë””ì˜¤ í ì´ˆê¸°í™”
                  _audioQueue.clear();
                  _currentTurnAudioBuffer = null;
                  
                  // 3. ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™
                  if (_onExitRequested != null) {
                    _onExitRequested!();
                  }
                } else {
                  // ì¼ë°˜ turn_complete (X ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì€ ê²½ìš°)
                  // ì˜¤ë””ì˜¤ë¥¼ ì •ìƒì ìœ¼ë¡œ ì¬ìƒ (ê³„ì† ëŒ€í™” ê°€ëŠ¥)
                  print("âœ… [LiveCamera] ì¼ë°˜ í„´ ì™„ë£Œ - ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ (ê³„ì† ëŒ€í™” ê°€ëŠ¥)");
                  // ì´ì „ ì¬ìƒì´ ê¼¬ì—¬ ìˆìœ¼ë©´ ì •ë¦¬ í›„ ìƒˆ í„´ ì¬ìƒ
                  _audioPlayer?.stop();
                  _isPlayingAudio = false;
                  _audioQueue.clear();
                  // ë¹„ë™ê¸° í•¨ìˆ˜ì´ì§€ë§Œ await ì—†ì´ í˜¸ì¶œ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
                  _finalizeAndPlayCurrentTurn();
                }
              }
            } catch (e) {
              print("âš ï¸ [LiveCamera] ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨: $e");
            }
          },
          onError: (error) {
            if (error.toString().contains('1011') || error.toString().contains('internal error')) {
              print("âš ï¸ [LiveCamera] ë°±ì—”ë“œ ì„œë²„ ì˜¤ë¥˜ (1011)");
              _channel?.sink.close();
              _channel = null;
              _websocketSubscription?.cancel();
              _websocketSubscription = null;
            } else {
              print("âŒ [LiveCamera] WebSocket ì—ëŸ¬: $error");
            }
          },
          onDone: () {
            print("ğŸ”Œ [LiveCamera] WebSocket ì—°ê²° ì¢…ë£Œ");
            _channel = null;
            _websocketSubscription = null;
          },
          cancelOnError: true,
        );
        
        // ì˜¤ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”
        print("ğŸ¤ [LiveCamera] ì˜¤ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”");
        try {
          _audioRecorder = AudioRecorder();
          final hasPermission = await _audioRecorder!.hasPermission();
          if (!hasPermission) {
            print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ë§Œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.");
          } else {
            // ê³µì‹ ì˜ˆì œ íŒ¨í„´: 16kHz, 16ë¹„íŠ¸ PCM, ëª¨ë…¸ ì˜¤ë””ì˜¤ ì „ì†¡
            // ê³µì‹ ë¬¸ì„œ: "ì˜¤ë””ì˜¤ë¥¼ 16ë¹„íŠ¸ PCM, 16kHz, ëª¨ë…¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì „ì†¡"
            // â­ ì¤‘ìš”: ì—ì½” ìº”ìŠ¬/AGCë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ AI ì¬ìƒ ì¤‘ì—ë„ ë…¹ìŒ ê°€ëŠ¥
            // âš ï¸ ì—ì½” ìº”ìŠ¬ì„ í™œì„±í™”í•˜ë©´ AI ì¬ìƒ ì¤‘ì— ë§ˆì´í¬ ì…ë ¥ì´ ì°¨ë‹¨ë  ìˆ˜ ìˆìŒ
            const config = RecordConfig(
              encoder: AudioEncoder.pcm16bits,
              sampleRate: 16000, // ê³µì‹ ë¬¸ì„œ: ì…ë ¥ì€ 16kHz
              numChannels: 1, // ëª¨ë…¸
              autoGain: false, // ìë™ ê²Œì¸ ë¹„í™œì„±í™” (AI ì¬ìƒ ì¤‘ì—ë„ ë…¹ìŒ ê°€ëŠ¥)
              echoCancel: false, // ì—ì½” ìº”ìŠ¬ ë¹„í™œì„±í™” (AI ì¬ìƒ ì¤‘ì—ë„ ë…¹ìŒ ê°€ëŠ¥)
              noiseSuppress: false, // ë…¸ì´ì¦ˆ ì–µì œ ë¹„í™œì„±í™” (AI ì¬ìƒ ì¤‘ì—ë„ ë…¹ìŒ ê°€ëŠ¥)
              audioInterruption: AudioInterruptionMode.none, // í¬ì»¤ìŠ¤ ë³€ë™ ì‹œ ìë™ pause ë°©ì§€
              androidConfig: AndroidRecordConfig(
                audioSource: AndroidAudioSource.voiceCommunication,
                speakerphone: true,
                audioManagerMode: AudioManagerMode.modeInCommunication,
              ),
            );
            
            Stream<Uint8List> stream;
            try {
              print("ğŸ¤ [LiveCamera] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹œë„...");
              stream = await _audioRecorder!.startStream(config);
              print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì„±ê³µ");
            } catch (e, stackTrace) {
              // ì¼ë¶€ ê¸°ê¸°ì—ì„œ voiceCommunication ì†ŒìŠ¤ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
              print("âš ï¸ [LiveCamera] ë§ì¶¤ ë…¹ìŒ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„: $e");
              print("âš ï¸ [LiveCamera] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: $stackTrace");
              try {
                stream = await _audioRecorder!.startStream(const RecordConfig(
                  encoder: AudioEncoder.pcm16bits,
                  sampleRate: 16000,
                  numChannels: 1,
                  autoGain: false,
                  echoCancel: false,
                  noiseSuppress: false,
                ));
                print("âœ… [LiveCamera] ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì„±ê³µ");
              } catch (e2) {
                print("âŒ [LiveCamera] ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œë„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹¤íŒ¨: $e2");
                rethrow;
              }
            }
            print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (ì—ì½” ìº”ìŠ¬ OFF, AI ì¬ìƒ ì¤‘ì—ë„ ë…¹ìŒ ê°€ëŠ¥)");
            
            // ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ (ì‚¬ìš©ì ë§í•˜ê¸° ê°ì§€ í¬í•¨)
            _audioStreamSubscription = stream.listen(
              (data) {
                if (_isStreaming && _channel != null) {
                  try {
                    // ë””ë²„ê¹…: ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  í™•ì¸
                    if (data.length > 0) {
                      print("ğŸ¤ [LiveCamera] ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ : ${data.length} bytes");
                    }
                    
                    // ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ (ë…¸ì´ì¦ˆ ë°©ì§€)
                    // PCM 16ë¹„íŠ¸ = 2 bytes per sample, 16kHz = 16000 samples/sec
                    // ìµœì†Œ 160 samples (10ms) ì´ìƒì¸ ê²½ìš°ë§Œ ì „ì†¡
                    if (data.length < 320) { // 160 samples * 2 bytes = 320 bytes
                      return; // ë„ˆë¬´ ì‘ì€ ì˜¤ë””ì˜¤ëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŒ
                    }
                    
                    final base64Audio = base64Encode(data);
                    _channel!.sink.add(jsonEncode({
                      'type': 'audio',
                      'data': base64Audio,
                    }));
                    
                    // ì‚¬ìš©ì ë§í•˜ê¸° ê°ì§€: ë§ˆì§€ë§‰ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œê°„ ì—…ë°ì´íŠ¸
                    _lastAudioSentTime = DateTime.now();
                    
                    // ì‚¬ìš©ì ë§í•˜ê¸° íƒ€ì´ë¨¸ ì¬ì„¤ì • (2ì´ˆ ë™ì•ˆ ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ë§ì„ ë©ˆì¶˜ ê²ƒìœ¼ë¡œ ê°„ì£¼)
                    _userSpeechTimer?.cancel();
                    _userSpeechTimer = Timer(const Duration(seconds: 2), () async {
                      // 2ì´ˆ ë™ì•ˆ ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìê°€ ë§ì„ ë©ˆì¶˜ ê²ƒìœ¼ë¡œ ê°„ì£¼
                      if (_isStreaming && _channel != null && _lastAudioSentTime != null) {
                        final timeSinceLastAudio = DateTime.now().difference(_lastAudioSentTime!);
                        if (timeSinceLastAudio.inSeconds >= 2) {
                          // ì‚¬ìš©ì ë§í•˜ê¸° ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
                          try {
                            _channel!.sink.add(jsonEncode({'type': 'user_speech_end'}));
                            print("âœ… [LiveCamera] ì‚¬ìš©ì ë§í•˜ê¸° ì¢…ë£Œ ê°ì§€ - user_speech_end ì‹ í˜¸ ì „ì†¡");
                            _lastAudioSentTime = null; // ë¦¬ì…‹
                          } catch (e) {
                            print("âš ï¸ [LiveCamera] ì‚¬ìš©ì ë§í•˜ê¸° ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ ì‹¤íŒ¨: $e");
                          }
                        }
                      }
                    });
                  } catch (e) {
                    print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨: $e");
                  }
                }
              },
              onError: (error) {
                print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬: $error");
                // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œì‘ ì‹œë„
                print("ğŸ”„ [LiveCamera] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¬ì‹œì‘ ì‹œë„...");
              },
            );
          }
        } catch (e) {
          print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™” ì‹¤íŒ¨: $e");
        }
        
        // ë¹„ë””ì˜¤ í”„ë ˆì„ ì „ì†¡ (0.5ì´ˆë§ˆë‹¤)
        _videoTimer = Timer.periodic(const Duration(milliseconds: 500), (timer) async {
          if (!_isStreaming || _cameraController == null || !_cameraController!.value.isInitialized || _channel == null) {
            return;
          }
          
          try {
            final image = await _cameraController!.takePicture().timeout(
              const Duration(seconds: 2),
              onTimeout: () => throw TimeoutException('ì¹´ë©”ë¼ ì´ë¯¸ì§€ ìº¡ì²˜ ì‹œê°„ ì´ˆê³¼'),
            );
            
            final imageFile = File(image.path);
            if (!await imageFile.exists()) {
              return;
            }
            
            final imageBytes = await imageFile.readAsBytes().timeout(
              const Duration(seconds: 2),
              onTimeout: () => throw TimeoutException('ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸° ì‹œê°„ ì´ˆê³¼'),
            );
            
            final base64Image = base64Encode(imageBytes);
            _channel!.sink.add(jsonEncode({
              'type': 'image',
              'data': base64Image,
            }));
          } catch (e) {
            // ì—ëŸ¬ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
          }
        });
      } else {
        print("âš ï¸ [LiveCamera] ë°±ì—”ë“œ ì—°ê²°ì´ ì—†ì–´ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      }
      
      print("âœ… [LiveCamera] ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì™„ë£Œ");
      return true;
    } catch (e) {
      print("âŒ [LiveCamera] ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹¤íŒ¨: $e");
      return false;
    }
  }
  
  Timer? _audioPlaybackTimer; // ì˜¤ë””ì˜¤ ì¬ìƒ íƒ€ì´ë¨¸ (ì¼ì • ì‹œê°„ í›„ ìë™ ì¬ìƒ)
  
  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ í˜„ì¬ í„´ ë²„í¼ì— ê³„ì† ì´ì–´ë¶™ì„
  // Python ì˜ˆì œì˜ wf.writeframes(response.data)ì™€ ë™ì¼í•œ íŒ¨í„´
  void _appendAudioChunk(Uint8List audioBytes) {
    try {
      // ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ (ë…¸ì´ì¦ˆ ë°©ì§€)
      if (audioBytes.length < 100) {
        return;
      }

      // ê³µì‹ ì˜ˆì œ íŒ¨í„´: í˜„ì¬ í„´ ë²„í¼ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (ìƒˆ í„´ ì‹œì‘)
      if (_currentTurnAudioBuffer == null) {
        _currentTurnAudioBuffer = Uint8List(0);
        print("ğŸ”Š [LiveCamera] ìƒˆ í„´ ì‹œì‘ - ì˜¤ë””ì˜¤ ë²„í¼ ì´ˆê¸°í™” (ì´ì „ í„´ ì™„ë£Œ)");
      }

      // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ì²­í¬ë¥¼ ë²„í¼ì— ì´ì–´ë¶™ì„ (ëê¹Œì§€ ê³„ì† ëˆ„ì )
      final newBuffer = Uint8List(_currentTurnAudioBuffer!.length + audioBytes.length);
      newBuffer.setRange(0, _currentTurnAudioBuffer!.length, _currentTurnAudioBuffer!);
      newBuffer.setRange(_currentTurnAudioBuffer!.length, newBuffer.length, audioBytes);
      _currentTurnAudioBuffer = newBuffer;

      print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€: ${audioBytes.length} bytes (ëˆ„ì : ${_currentTurnAudioBuffer!.length} bytes)");
      
      // ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì˜¤ë©´ ê¸°ì¡´ íƒ€ì´ë¨¸ ì·¨ì†Œí•˜ê³  ìƒˆ íƒ€ì´ë¨¸ ì‹œì‘
      // ì¼ì • ì‹œê°„(ì˜ˆ: 1ì´ˆ) ë™ì•ˆ ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì˜¤ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ì¬ìƒ ì‹œì‘
      _audioPlaybackTimer?.cancel();
      _audioPlaybackTimer = Timer(const Duration(seconds: 1), () {
        // 1ì´ˆ ë™ì•ˆ ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì˜¤ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ì¬ìƒ ì‹œì‘
        if (_currentTurnAudioBuffer != null && _currentTurnAudioBuffer!.isNotEmpty && !_isPlayingAudio) {
          print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  ì¤‘ë‹¨ ê°ì§€ - ìë™ ì¬ìƒ ì‹œì‘");
          _finalizeAndPlayCurrentTurn();
        }
      });
    } catch (e) {
      print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ ì‹¤íŒ¨: $e");
    }
  }
  
  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: í„´ì´ ëë‚  ë•Œê¹Œì§€ ë°›ì€ ëª¨ë“  ì˜¤ë””ì˜¤ë¥¼ WAVë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ
  // Python ì˜ˆì œì˜ wf.close()ì™€ ì¬ìƒ ì‹œì‘ì— í•´ë‹¹
  Future<void> _finalizeAndPlayCurrentTurn() async {
    try {
      if (_currentTurnAudioBuffer == null || _currentTurnAudioBuffer!.isEmpty) {
        print("âš ï¸ [LiveCamera] í˜„ì¬ í„´ì— ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }

      if (_audioPlayer == null) {
        print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
        return;
      }

      // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ì¶œë ¥ì€ 24kHz PCM
      // ê³µì‹ ë¬¸ì„œ: "ì¶œë ¥ì€ ìƒ˜í”Œë§ ë ˆì´íŠ¸ 24kHzë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤"
      // ë²„í¼ë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì— ë³µì‚¬ (ë²„í¼ë¥¼ nullë¡œ ì„¤ì •í•˜ê¸° ì „ì— ì‚¬ìš©)
      final bufferToUse = _currentTurnAudioBuffer!;
      final wavBytes = _pcmToWav(bufferToUse, sampleRate: 24000, channels: 1, bitsPerSample: 16);
      
      // ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
      final tempDir = Directory.systemTemp;
      final tempFile = File('${tempDir.path}/ai_audio_turn_${DateTime.now().millisecondsSinceEpoch}.wav');
      await tempFile.writeAsBytes(wavBytes);
      
      print("ğŸ”Š [LiveCamera] í„´ ì™„ë£Œ - ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±: ${wavBytes.length} bytes (ì›ë³¸ PCM: ${bufferToUse.length} bytes)");
      
      // ì¤‘ìš”: WAV íŒŒì¼ì„ ë§Œë“  í›„ ì¦‰ì‹œ ë²„í¼ë¥¼ nullë¡œ ì„¤ì •í•˜ì—¬ ë‹¤ìŒ í„´ì„ ì¤€ë¹„
      // ë‹¤ìŒ ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì˜¤ë©´ _appendAudioChunkì—ì„œ ìë™ìœ¼ë¡œ ìƒˆ ë²„í¼ë¥¼ ì´ˆê¸°í™”í•¨
      _currentTurnAudioBuffer = null; // ë‹¤ìŒ í„´ì„ ìœ„í•´ ì¦‰ì‹œ ì´ˆê¸°í™”
      print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ ë²„í¼ ì´ˆê¸°í™” ì™„ë£Œ (ë‹¤ìŒ í„´ ì¤€ë¹„, ì¬ìƒì€ ê³„ì†ë¨)");
      
      // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ì¤‘ê°„ì— stop/reset í•˜ì§€ ì•Šê³  ëê¹Œì§€ ì¬ìƒ
      // ì¬ìƒ ì¤‘ì´ ì•„ë‹ˆë©´ ì¦‰ì‹œ ì¬ìƒ, ì¬ìƒ ì¤‘ì´ë©´ íì— ì¶”ê°€
      if (!_isPlayingAudio) {
        _isPlayingAudio = true;
        
        // â­ ì¤‘ìš”: ë³¼ë¥¨ì„ ëª…ì‹œì ìœ¼ë¡œ ìµœëŒ€ë¡œ ì„¤ì • í›„ ì¬ìƒ
        try {
          await _audioPlayer!.setVolume(1.0);
          print("ğŸ”Š [LiveCamera] ë³¼ë¥¨ ì„¤ì • ì™„ë£Œ: 1.0");
          
          // íŒŒì¼ ì¡´ì¬ í™•ì¸
          if (!await tempFile.exists()) {
            print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${tempFile.path}");
            _isPlayingAudio = false;
            return;
          }
          
          print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ íŒŒì¼ ì¬ìƒ ì‹œë„: ${tempFile.path} (í¬ê¸°: ${wavBytes.length} bytes)");
          await _audioPlayer!.play(DeviceFileSource(tempFile.path), volume: 1.0);
          print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ ì„±ê³µ: ${wavBytes.length} bytes (ë³¼ë¥¨: 100%)");
          
          // ì¬ìƒ ìƒíƒœ í™•ì¸ (1ì´ˆ í›„)
          Future.delayed(const Duration(seconds: 1), () {
            if (_audioPlayer != null) {
              print("ğŸ”Š [LiveCamera] ì¬ìƒ 1ì´ˆ í›„ ìƒíƒœ í™•ì¸: ${_audioPlayer!.state}");
              print("ğŸ”Š [LiveCamera] í˜„ì¬ ë³¼ë¥¨: ${_audioPlayer!.volume}");
            }
          });
        } catch (playError, stackTrace) {
          print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $playError");
          print("âŒ [LiveCamera] ì—ëŸ¬ íƒ€ì…: ${playError.runtimeType}");
          print("âŒ [LiveCamera] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: $stackTrace");
          _isPlayingAudio = false;
          // ì¬ìƒ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        }
        
        // ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ë“±ë¡
        _audioPlayer!.onPlayerComplete.first.then((_) {
          print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ");
          tempFile.delete().catchError((_) => tempFile);
          _isPlayingAudio = false;
          
          // ë²„í¼ëŠ” ì´ë¯¸ _finalizeAndPlayCurrentTurnì—ì„œ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
          
          // íì— ëŒ€ê¸° ì¤‘ì¸ ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ ì¬ìƒ
          if (_audioQueue.isNotEmpty) {
            _processAudioQueue();
          }
        }).catchError((error) {
          print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ì—ëŸ¬: $error");
          _isPlayingAudio = false;
          // ì—ëŸ¬ê°€ ë‚˜ë„ ë²„í¼ëŠ” ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ ì´ˆê¸°í™”í•  í•„ìš” ì—†ìŒ
        });
      } else {
        // ì¬ìƒ ì¤‘ì´ë©´ íì— ì¶”ê°€ (ì—°ì† ì¬ìƒ)
        _audioQueue.add(tempFile);
        print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ íì— ì¶”ê°€ (ì¬ìƒ ì¤‘, í í¬ê¸°: ${_audioQueue.length})");
      }
      
      // ë²„í¼ëŠ” ì´ë¯¸ ìœ„ì—ì„œ nullë¡œ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¶”ê°€ ì‘ì—… ë¶ˆí•„ìš”
    } catch (e) {
      print("âŒ [LiveCamera] í„´ ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: $e");
      _currentTurnAudioBuffer = null;
      _isPlayingAudio = false;
    }
  }

  
  // ì˜¤ë””ì˜¤ í ì²˜ë¦¬ (ì—°ì† ì¬ìƒ)
  Future<void> _processAudioQueue() async {
    if (_isPlayingAudio || _audioQueue.isEmpty) {
      return;
    }
    
    _isPlayingAudio = true;
    
    try {
      await _playNextAudio();
    } catch (e) {
      print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ í ì²˜ë¦¬ ì‹¤íŒ¨: $e");
      _isPlayingAudio = false;
    }
  }
  
  // ë‹¤ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ (ë‚´ë¶€ í•¨ìˆ˜)
  Future<void> _playNextAudio() async {
    if (_audioQueue.isEmpty || _audioPlayer == null) {
      _isPlayingAudio = false;
      print("âš ï¸ [LiveCamera] ì˜¤ë””ì˜¤ íê°€ ë¹„ì–´ìˆê±°ë‚˜ í”Œë ˆì´ì–´ê°€ ì—†ìŠµë‹ˆë‹¤");
      return;
    }
    
    final audioFile = _audioQueue.removeAt(0);
    final fileSize = await audioFile.length();
    
    try {
      // â­ ì¤‘ìš”: ë³¼ë¥¨ì„ ëª…ì‹œì ìœ¼ë¡œ ìµœëŒ€ë¡œ ì„¤ì • í›„ ì¬ìƒ
      await _audioPlayer!.setVolume(1.0);
      print("ğŸ”Š [LiveCamera] ë³¼ë¥¨ ì„¤ì • ì™„ë£Œ: 1.0");
      
      // íŒŒì¼ ì¡´ì¬ í™•ì¸
      if (!await audioFile.exists()) {
        print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${audioFile.path}");
        _isPlayingAudio = false;
        return;
      }
      
      print("ğŸ”Š [LiveCamera] ì˜¤ë””ì˜¤ íŒŒì¼ ì¬ìƒ ì‹œë„: ${audioFile.path} (í¬ê¸°: $fileSize bytes)");
      await _audioPlayer!.play(DeviceFileSource(audioFile.path), volume: 1.0);
      print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ ì„±ê³µ: $fileSize bytes (í ë‚¨ì€ ê°œìˆ˜: ${_audioQueue.length}, ë³¼ë¥¨: 100%)");
      
      // ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ë“±ë¡ (í•œ ë²ˆë§Œ ì‹¤í–‰)
      _audioPlayer!.onPlayerComplete.first.then((_) {
        print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ: ${fileSize} bytes");
        
        // íŒŒì¼ ì‚­ì œ
        audioFile.delete().catchError((_) {
          return audioFile;
        });

        // ë‹¤ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ (ì¦‰ì‹œ)
        if (_audioQueue.isNotEmpty) {
          print("ğŸ”„ [LiveCamera] ë‹¤ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ (í: ${_audioQueue.length}ê°œ)");
          _playNextAudio();
        } else {
          _isPlayingAudio = false;
          print("âœ… [LiveCamera] ì˜¤ë””ì˜¤ í ì¬ìƒ ì™„ë£Œ (ëª¨ë“  íŒŒì¼ ì¬ìƒë¨)");
        }
      }).catchError((error) {
        print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ì—ëŸ¬: $error");
        // ì—ëŸ¬ê°€ ë‚˜ë„ ë‹¤ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„
        if (_audioQueue.isNotEmpty) {
          Future.delayed(const Duration(milliseconds: 50), () {
            _playNextAudio();
          });
        } else {
          _isPlayingAudio = false;
        }
      });
    } catch (e) {
      print("âŒ [LiveCamera] ì˜¤ë””ì˜¤ íŒŒì¼ ì¬ìƒ ì‹¤íŒ¨: $e");
      audioFile.delete().catchError((_) {
        return audioFile;
      });
      
      // ì¬ìƒ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ (ì§§ì€ ì§€ì—°)
      if (_audioQueue.isNotEmpty) {
        await Future.delayed(const Duration(milliseconds: 50));
        await _playNextAudio();
      } else {
        _isPlayingAudio = false;
      }
    }
  }
  
  
  // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
  Future<void> stopStreaming() async {
    _isStreaming = false;
    
    _videoTimer?.cancel();
    _videoTimer = null;
    
    _audioTimer?.cancel();
    _audioTimer = null;
    
    await _audioStreamSubscription?.cancel();
    _audioStreamSubscription = null;
    
    await _audioRecorder?.stop();
    await _audioRecorder?.dispose();
    _audioRecorder = null;
    
    await _websocketSubscription?.cancel();
    _websocketSubscription = null;
    
    await _channel?.sink.close();
    _channel = null;
    
    await _cameraController?.dispose();
    _cameraController = null;
    
    // ì˜¤ë””ì˜¤ í ì´ˆê¸°í™”
    _audioQueue.clear();
    _pendingAudioChunks.clear();
    _audioFlushTimer?.cancel();
    _audioFlushTimer = null;
    
    // ê³µì‹ ì˜ˆì œ íŒ¨í„´: í˜„ì¬ í„´ ë²„í¼ ì´ˆê¸°í™”
    _currentTurnAudioBuffer = null;
    
    // ì‚¬ìš©ì ë§í•˜ê¸° ê°ì§€ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    _userSpeechTimer?.cancel();
    _userSpeechTimer = null;
    _lastAudioSentTime = null;
    
    // Firebase ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
    if (_sessionId != null) {
      try {
        await FirebaseFirestore.instance
            .collection('sessions')
            .doc(_sessionId)
            .update({'status': 'completed'});
      } catch (e) {
        // ì—ëŸ¬ ë¬´ì‹œ
      }
    }
    
    print("âœ… [LiveCamera] ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ì™„ë£Œ");
  }
  
  // ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ëŸ¬ ë°˜í™˜
  CameraController? get cameraController => _cameraController;
  
  // í•œêµ­ì–´ë§Œ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
  bool _containsKorean(String text) {
    final koreanRegex = RegExp(r'[ê°€-í£ã„±-ã…ã…-ã…£]');
    return koreanRegex.hasMatch(text);
  }
  
  // ì˜ì–´ë§Œ ìˆëŠ”ì§€ í™•ì¸
  bool _isEnglishOnly(String text) {
    final englishOnlyRegex = RegExp(r"^[a-zA-Z0-9\s\.,!?;:\-()]+$");
    return englishOnlyRegex.hasMatch(text.trim()) && !_containsKorean(text);
  }
  
  // PCMì„ WAVë¡œ ë³€í™˜
  Uint8List _pcmToWav(Uint8List pcmData, {required int sampleRate, required int channels, required int bitsPerSample}) {
    final dataSize = pcmData.length;
    final byteRate = sampleRate * channels * (bitsPerSample ~/ 8);
    final blockAlign = channels * (bitsPerSample ~/ 8);
    
    final wavHeader = Uint8List(44);
    var offset = 0;
    
    void writeInt(int value, int bytes) {
      for (int i = 0; i < bytes; i++) {
        wavHeader[offset + i] = (value >> (i * 8)) & 0xFF;
      }
      offset += bytes;
    }
    
    void writeString(String str) {
      for (int i = 0; i < str.length; i++) {
        wavHeader[offset + i] = str.codeUnitAt(i);
      }
      offset += str.length;
    }
    
    writeString('RIFF');
    writeInt(dataSize + 36, 4);
    writeString('WAVE');
    writeString('fmt ');
    writeInt(16, 4);
    writeInt(1, 2);
    writeInt(channels, 2);
    writeInt(sampleRate, 4);
    writeInt(byteRate, 4);
    writeInt(blockAlign, 2);
    writeInt(bitsPerSample, 2);
    writeString('data');
    writeInt(dataSize, 4);
    
    return Uint8List.fromList([...wavHeader, ...pcmData]);
  }
  
  // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ
  bool get isStreaming => _isStreaming;
  
  // ì—˜ë¦¬í™ˆìœ¼ë¡œ ì´ë™ ì½œë°± ì„¤ì •
  void setOnExitRequested(VoidCallback? callback) {
    _onExitRequested = callback;
  }
  
  // X ë²„íŠ¼ í´ë¦­ ì‹œ í˜¸ì¶œ: ì§„ë‹¨ í™”ë©´ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
  void closeDiagnosisAndExit() {
    if (_channel != null) {
      try {
        _channel!.sink.add(jsonEncode({
          'type': 'close_diagnosis',
        }));
        print("âœ… [LiveCamera] ì§„ë‹¨ í™”ë©´ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ (X ë²„íŠ¼ í´ë¦­)");
      } catch (e) {
        print("âŒ [LiveCamera] ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ ì‹¤íŒ¨: $e");
      }
    } else {
      print("âš ï¸ [LiveCamera] WebSocket ì—°ê²°ì´ ì—†ì–´ ì¢…ë£Œ ì‹ í˜¸ë¥¼ ì „ì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }
  }
}
